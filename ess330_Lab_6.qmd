---
title: "ess330_Lab_6"
author: "Chloe Rogozinski"
date: "2025-03-31"
format: html
execute:
  echo: true
---

## Lab 6 ## 

#Lab SetUp
```{r}
library(tidyverse)
library(tidymodels)
library(powerjoin)
library(glue)
library(vip)
library(baguette)
```

```{r}
#download data and get PDF
root  <- 'https://gdex.ucar.edu/dataset/camels/file'

download.file('https://gdex.ucar.edu/dataset/camels/file/camels_attributes_v2.0.pdf', 
              'data/camels_attributes_v2.0.pdf')
```

Getting Basin characteristics
```{r}
#a
types <- c("clim", "geol", "soil", "topo", "vege", "hydro")

#b
# Where the files live online ...
remote_files  <- glue('{root}/camels_{types}.txt')
# where we want to download the data ...
local_files   <- glue('data/camels_{types}.txt')

#c
walk2(remote_files, local_files, download.file, quiet = TRUE)

#d
# Read and merge data
camels <- map(local_files, read_delim, show_col_types = FALSE) 

#e
camels <- power_full_join(camels ,by = 'gauge_id')

```

#Question 1:

Answer:
The data files and PDF are downloaded and was placed into my data folder. In the PDF, zero_q_freq represents the frequency of days with Q = 0 mm/day and is represented as percentage.

```{r}
#make map of the sites
ggplot(data = camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = q_mean)) +
  scale_color_gradient(low = "pink", high = "dodgerblue") +
  ggthemes::theme_map()
```

## Question 2 ##

```{r}
#make 2 maps
library(ggplot2)
library(ggthemes)
library(patchwork)  

#Map 1: Aridity
map_aridity <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = aridity)) +
  scale_color_gradient(low = "tan", high = "darkred") +
  labs(title = "CAMELS Basins Colored by Aridity",
       x = "Longitude", y = "Latitude", color = "Aridity") +
  ggthemes::theme_map()

#Map 2: Mean Precipitation
map_precip <- ggplot(camels, aes(x = gauge_lon, y = gauge_lat)) +
  borders("state", colour = "gray50") +
  geom_point(aes(color = p_mean)) +
  scale_color_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "CAMELS Basins Colored by Mean Precipitation (p_mean)",
       x = "Longitude", y = "Latitude", color = "p_mean (mm)") +
  ggthemes::theme_map()

#Combine 
map_aridity + map_precip

```


```{r}
#Model Prep
camels |> 
  select(aridity, p_mean, q_mean) |> 
  drop_na() |> 
  cor()
```

#visual EDA
```{r}
#Looking at 3 variables
# Create a scatter plot of aridity vs rainfall
ggplot(camels, aes(x = aridity, y = p_mean)) +
  # Add points colored by mean flow
  geom_point(aes(color = q_mean)) +
  # Add a linear regression line
  geom_smooth(method = "lm", color = "red", linetype = 2) +
  # Apply the viridis color scale
  scale_color_viridis_c() +
  # Add a title, axis labels, and theme (w/ legend on the bottom)
  theme_linedraw() + 
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```
```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  scale_color_viridis_c() +
  # Apply log transformations to the x and y axes
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom") + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow")
```

```{r}
ggplot(camels, aes(x = aridity, y = p_mean)) +
  geom_point(aes(color = q_mean)) +
  geom_smooth(method = "lm") +
  # Apply a log transformation to the color scale
  scale_color_viridis_c(trans = "log") +
  scale_x_log10() + 
  scale_y_log10() +
  theme_linedraw() +
  theme(legend.position = "bottom",
        # Expand the legend width ...
        legend.key.width = unit(2.5, "cm"),
        legend.key.height = unit(.5, "cm")) + 
  labs(title = "Aridity vs Rainfall vs Runnoff", 
       x = "Aridity", 
       y = "Rainfall",
       color = "Mean Flow") 
```
#Model Building
```{r}
set.seed(123)
# Bad form to perform simple transformations on the outcome variable within a 
# recipe. So, we'll do it here.
camels <- camels |> 
  mutate(logQmean = log(q_mean))

# Generate the split
camels_split <- initial_split(camels, prop = 0.8)
camels_train <- training(camels_split)
camels_test  <- testing(camels_split)

camels_cv <- vfold_cv(camels_train, v = 10)
```

#preprocessor
```{r}
# Create a recipe to preprocess the data
rec <-  recipe(logQmean ~ aridity + p_mean, data = camels_train) %>%
  # Log transform the predictor variables (aridity and p_mean)
  step_log(all_predictors()) %>%
  # Add an interaction term between aridity and p_mean
  step_interact(terms = ~ aridity:p_mean) |> 
  # Drop any rows with missing values in the pred
  step_naomit(all_predictors(), all_outcomes())
```


#Naive base lm approach
```{r}
# Prepare the data
baked_data <- prep(rec, camels_train) |> 
  bake(new_data = NULL)

# Interaction with lm
#  Base lm sets interaction terms with the * symbol
lm_base <- lm(logQmean ~ aridity * p_mean, data = baked_data)
summary(lm_base)
```
```{r}
# Sanity Interaction term from recipe ... these should be equal!!
summary(lm(logQmean ~ aridity + p_mean + aridity_x_p_mean, data = baked_data))
```

#wrong version 1
```{r}
nrow(camels_test)

nrow(camels_train)

```

#Wrong version 2
```{r}
camels_test$p2 = predict(lm_base, newdata = camels_test)

## Scales way off!
ggplot(camels_test, aes(x = p2, y = logQmean)) + 
  geom_point() + 
  # Linear fit line, no error bands
  geom_smooth(method = "lm", se = FALSE, size =1) +
  # 1:1 line
  geom_abline(color = "red", size = 1) + 
  labs(title = "Linear Model Using `predict()`",
       x = "Predicted Log Mean Flow",
       y = "Observed Log Mean Flow") + 
  theme_linedraw()
```

#Correct version
```{r}
#preprocessing
test_data <-  bake(prep(rec), new_data = camels_test)
test_data$lm_pred <- predict(lm_base, newdata = test_data)

#model Eval.
metrics(test_data, truth = logQmean, estimate = lm_pred)

#view
ggplot(test_data, aes(x = logQmean, y = lm_pred, colour = aridity)) +
  # Apply a gradient color scale
  scale_color_gradient2(low = "brown", mid = "orange", high = "darkgreen") +
  geom_point() +
  geom_abline(linetype = 2) +
  theme_linedraw() + 
  labs(title = "Linear Model: Observed vs Predicted",
       x = "Observed Log Mean Flow",
       y = "Predicted Log Mean Flow",
       color = "Aridity")

```

#Using wrokflow
```{r}
# Define model
lm_model <- linear_reg() %>%
  # define the engine
  set_engine("lm") %>%
  # define the mode
  set_mode("regression")

# Instantiate a workflow ...
lm_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(lm_model) %>%
  # Fit the model to the training data
  fit(data = camels_train) 

# Extract the model coefficients from the workflow
summary(extract_fit_engine(lm_wf))$coefficients

# From the base implementation
summary(lm_base)$coefficients
```

#Making Predictions
```{r}
#
lm_data <- augment(lm_wf, new_data = camels_test)
dim(lm_data)
```

#Model Eval: Stats. and visual
```{r}
metrics(lm_data, truth = logQmean, estimate = .pred)

ggplot(lm_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()

```

#Switch it up
```{r}
library(baguette)
rf_model <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")

rf_wf <- workflow() %>%
  # Add the recipe
  add_recipe(rec) %>%
  # Add the model
  add_model(rf_model) %>%
  # Fit the model
  fit(data = camels_train) 
```

#predictions
```{r}
rf_data <- augment(rf_wf, new_data = camels_test)
dim(rf_data)

#model eval.
metrics(rf_data, truth = logQmean, estimate = .pred)

ggplot(rf_data, aes(x = logQmean, y = .pred, colour = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline() +
  theme_linedraw()
```

#a workflow approach
```{r}
wf <- workflow_set(list(rec), list(lm_model, rf_model)) %>%
  workflow_map('fit_resamples', resamples = camels_cv) 

autoplot(wf)

rank_results(wf, rank_metric = "rsq", select_best = TRUE)
```

## Question 3: Build 2 models ##
```{r}
#Model 1
library(xgboost)

xgb_model <- boost_tree(trees = 1000) %>%
  set_engine("xgboost") %>%
  set_mode("regression")

```
```{r}
#Model 2
nn_model <- bag_mlp() %>%
  set_engine("nnet") %>%
  set_mode("regression")

```

```{r}
#combine models in workflow set
models <- list(
  lm_model,
  rf_model,
  xgb_model,
  nn_model
)

wf_set <- workflow_set(
  preproc = list(rec),
  models = models
) %>%
  workflow_map("fit_resamples", resamples = camels_cv)
#evaluate
autoplot(wf_set) 

#rank by R-squared
rank_results(wf_set, rank_metric = "rsq", select_best = TRUE)

```

#answer:
After evaluating the 4 models, I would go with the nueral network was the best performing. With the highest R-squared and the lowest RMSE across the 10 fold cross validation.

## Question 4: Build your own ##
#Q4a: data splitting
```{r}
set.seed(123) 

camels_split_4 <- initial_split(camels, prop = 0.75)
camels_train_4 <- training(camels_split_4)
camels_test_4  <- testing(camels_split_4)

camels_cv_4 <- vfold_cv(camels_train_4, v = 10)

```

#Q4b: Recipe
```{r}
rec_4 <- recipe(logQmean ~ area_gages2 + slope_mean + p_mean + pet_mean + aridity + frac_forest, 
                data = camels_train_4) %>%
  step_log(all_predictors(), offset = 1e-6) %>%  
  step_normalize(all_predictors()) %>%
  step_naomit(all_predictors(), all_outcomes())


```

#answer
I chose this formula because it includes key physical and climatic drivers of streamflow: basin area, slope, precipitation, evapotranspiration, aridity, and forest cover. These variables influence water availability and movement across the landscape.

#Q4c Define 3 models
```{r}
#model 1
rf_4 <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("regression")
#model 2
xgb_4 <- boost_tree(trees = 1000) %>%
  set_engine("xgboost") %>%
  set_mode("regression")
#model 3
nn_4 <- bag_mlp() %>%
  set_engine("nnet") %>%
  set_mode("regression")

```

#Q4d workflow set
```{r}
wf_4 <- workflow_set(
  preproc = list(rec_4),  
  models = list(
    random_forest = rf_4,
    xgboost = xgb_4,
    neural_net = nn_4
  )
) %>%
  workflow_map("fit_resamples", resamples = camels_cv_4)

```

#Q4e evaluation
```{r}
#autoplot
autoplot(wf_4)

#Rank
rank_results(wf_4, rank_metric = "rsq", select_best = TRUE)

```

#answer:
Out of the three models tested, the XGBoost model was the best performing. It had the lowest RMSE and the highest R^2 across all the resamples. This means it was the most reliable predictor of mean stream flow.

#Q4f Extact and Evaluate
```{r}
#Build final workflow
final_wf <- workflow() %>%
  add_recipe(rec_4) %>%
  add_model(xgb_4)

#Fit the model
final_fit <- final_wf %>%
  fit(data = camels_train_4)

#Predict
final_preds <- augment(final_fit, new_data = camels_test_4)

#Get metrics
metrics(final_preds, truth = logQmean, estimate = .pred)

#Plot observed vs predicted
ggplot(final_preds, aes(x = logQmean, y = .pred, color = aridity)) +
  scale_color_viridis_c() +
  geom_point() +
  geom_abline(linetype = "dashed") +
  labs(
    title = "XGBoost Final Model: Observed vs Predicted Log Mean Flow",
    x = "Observed Log Mean Flow",
    y = "Predicted Log Mean Flow",
    color = "Aridity"
  ) +
  theme_linedraw()

```

#answer:
The XGBoost model performed well overall, especially for lower aridity values where most predictions lined up closely with observed values. As aridity increased, predictions became more spread out, which makes sense since flow is harder to predict in more arid regions. Still, the model held up well and shows strong potential for general streamflow prediction.







